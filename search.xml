<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Redis-持久化与缓存</title>
      <link href="/2022/05/11/Redis-%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%8E%E7%BC%93%E5%AD%98/"/>
      <url>/2022/05/11/Redis-%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%8E%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-持久化与缓存"><a href="#Redis-持久化与缓存" class="headerlink" title="Redis-持久化与缓存"></a>Redis-持久化与缓存</h1><h2 id="1-Redis持久化机制"><a href="#1-Redis持久化机制" class="headerlink" title="1.Redis持久化机制"></a>1.Redis持久化机制</h2><p>为了能够重用<code>Redis</code>数据，或者防止系统故障，我们需要将<code>Redis</code>中的数据写入到磁盘空间中，即持久化。<code>Redis</code>提供了两种不同的持久化方法可以将数据存储在磁盘中，一种叫快照<code>RDB</code>，另一种叫只追加文件<code>AOF</code>。</p><ol><li><p><strong>RDB：</strong>在指定的时间间隔内将内存中的数据集快照写入磁盘，它恢复时是将快照文件直接读到内存里。<br>保存的时间策略：</p><pre class=" language-sh"><code class="language-sh">save 3600 1 #3600 秒1次key变更save 300 100 #300秒100次key变更save 60 10000 #60 秒10000次key变更dbfilename dump.rdb ##存储文件名dir ./  ##存储路径</code></pre><p><strong>流程：</strong>1).  <code>Redis</code>会单独创建（fork）一个子进程来进行持久化<code>bgsave(background save)</code>，即异步不阻塞的方式；2).  再将数据写入到一个临时文件中，待持久化过程都结束，再用这个临时文件替换上次持久化好的文件。<br><strong>优势</strong>：整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能；适合大规模的数据恢复；对数据完整性和一致性要求不高。<br><strong>劣势</strong>：<code>RDB</code>方案需要一定的触发条件才去做快照工作，可能会丢失最近一段时间内的数据。</p></li><li><p><strong>AOF：</strong>以日志的形式来记录增量操作（写操作），将 <code>Redis</code>执行过的所有写指令记录下来 (读操作不记录)， 只许追加文件但不可以改写文件，<code>Redis</code>启动之初会读取该文件重新构建数据。</p><p><strong>流程：</strong>1).  客户端的请求写命令会被追加（append）到 <code>AOF</code> 缓冲区内；2).  <code>AOF</code>缓冲区根据<code>AOF</code>持久化策略 [<strong>always</strong>(同步写回), <strong>everysec</strong>(异步写回), <strong>no</strong>(异步写回，由系统触发)] 将操作<code>sync</code>同步到磁盘的<code>AOF</code>文件中；3).  <code>AOF</code> 文件大小超过重写策略或手动重写时，会对<code>AOF</code> 文件 rewrite 重写（<strong>因为最终目的是恢复数据，所以存在一些无用的指令</strong>），压缩<code>AOF</code>文件容量；4).  <code>Redis</code>服务重启时，会重新 load 加载<code>AOF</code>文件中的写操作达到数据恢复的目的。<br><strong>优势</strong>：<code>AOF</code>方法比较安全。<br><strong>劣势</strong>：文件大，一条条命令执行来恢复数据，时间长、效率低。</p></li><li><p><strong>混合持久化</strong>：RDB+AOF<br><strong>流程：</strong><code>AOF</code>在重写时，先将重写这一时刻之前的数据集做<code>RDB</code>快照处理，在这期间如果有新的操作，就将增量的<code>AOF</code>修改命令与<code>RDB</code>快照合并在一起，替换原来的<code>AOF</code>文件。在恢复时，先恢复<code>RDB</code>部分，在执行少量的<code>AOF</code>命令。这样既保证效率又安全。<br><strong>优势</strong>：混合持久化结合了<code>RDB</code>持久化 和<code>AOF</code>持久化的优点， 由于绝大部分都是<code>RDB</code>格式，加载速度快，同时结合<code>AOF</code>，增量的数据以<code>AOF</code>方式保存了，数据更少的丢失。<br><strong>劣势</strong>：兼容性差，一旦开启了混合持久化，在4.0之前版本都不识别该<code>AOF</code>文件，同时由于前部分是<code>RDB</code>格式，阅读性较差。</p></li></ol><blockquote><p>如何选择合适的持久化方式</p></blockquote><ul><li>如果是数据不那么敏感，且可以从其他地方重新生成补回的，那么可以关闭持久化。</li><li>如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用RDB。</li><li>如果是用做内存数据库，要使用Redis的持久化，建议是RDB和AOF都开启，或者定期执行bgsave做快照备份，RDB方式更适合做数据的备份，AOF可以保证数据的不丢失。</li></ul><h2 id="2-Redis过期键的删除策略"><a href="#2-Redis过期键的删除策略" class="headerlink" title="2.Redis过期键的删除策略"></a>2.Redis过期键的删除策略</h2><p><strong>1、定时删除</strong></p><p>在设置键的过期时间的同时，创建一个定时器 timer。 让定时器在键的过期时间来临时，立即执行对键的删除操作。</p><p>优点：定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。</p><p>缺点：对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 时间，对服务器的响应时间和吞吐量造成影响。</p><p><strong>2、惰性删除</strong></p><p>放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。</p><p>优点：对 CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的键不用浪费时间进行过期检查。</p><p>缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键所占用的内存永远不会释放，从而造成内存泄漏。</p><p><strong>3、定期删除</strong></p><p>每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。</p><p>优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。</p><p>缺点：难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。</p><blockquote><p>通过<code>expire</code>或<code>pexpire</code>命令，客户端可以<strong>以秒或毫秒</strong>的精度为数据库中的某个键设置生存时间。</p><p>此外，客户端可以通过<code>expireat</code>和<code>pexpireat</code>命令，以秒或毫秒精度给数据库中的某个键设置过期时间，可以理解为：让某个键在某个时间点过期。</p></blockquote><h2 id="3-Redis内存淘汰策略"><a href="#3-Redis内存淘汰策略" class="headerlink" title="3. Redis内存淘汰策略"></a>3. Redis内存淘汰策略</h2><p>当Redis的内存超过最大允许的内存之后（很多没有设置过期时间的数据也会越来越多），<code>Redis</code>会触发内存淘汰策略，删除一些不常用的数据，以保证<code>Redis</code>服务器的正常运行。</p><p><strong>Redisv4.0前提供6种数据淘汰策略</strong>：</p><ul><li>volatile-lru：利用LRU算法移除设置过过期时间的key (LRU:最近最少使用Least Recently Used)</li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）</li><li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li><li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li><li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li><li>no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。(不常用)</li></ul><p><strong>Redisv4.0后增加以下两种</strong>：</p><ul><li>volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰(LFU: Least Frequently Used)算法，也就是最频繁被访问的数据将来最有可能被访问到)                                          </li><li>allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。</li></ul><blockquote><p>内存淘汰策略可以通过配置文件来修改，Redis.conf对应的配置项是maxmemory-policy 修改对应的值就行，默认是no-eviction。</p></blockquote><h2 id="4-如何保证缓存与数据库双写时的数据一致性"><a href="#4-如何保证缓存与数据库双写时的数据一致性" class="headerlink" title="4.如何保证缓存与数据库双写时的数据一致性"></a>4.如何保证缓存与数据库双写时的数据一致性</h2><p><strong>1.先更新数据库，后更新缓存</strong></p><p>存在的问题：并发更新数据库场景下，会将脏数据刷到缓存。</p><p><strong>2.先更新缓存，后更新数据库</strong></p><p>存在的问题：如果先更新缓存成功，但是数据库更新失败，则肯定会造成数据不一致。</p><p><strong>3.先删除缓存，后更新数据库</strong></p><p>该方案也会出问题，此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p><ol><li>请求A进行写操作，删除缓存</li><li>请求B查询发现缓存不存在</li><li>请求B去数据库查询得到旧值</li><li>请求B将旧值写入缓存</li><li>请求A将新值写入数据库</li></ol><p>上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p><ul><li><strong>解决方案：延时双删</strong></li></ul><p>最简单的解决办法延时双删</p><p>使用伪代码如下：</p><pre class=" language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>String key<span class="token punctuation">,</span>Object data<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    Redis<span class="token punctuation">.</span><span class="token function">delKey</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>    db<span class="token punctuation">.</span><span class="token function">updateData</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>    Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Redis<span class="token punctuation">.</span><span class="token function">delKey</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>转化为中文描述就是<br>（1）先淘汰缓存<br>（2）再写数据库（这两步和原来一样）<br>（3）休眠1秒，再次淘汰缓存，这么做，可以将1秒内所造成的缓存脏数据，再次删除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。自行评估自己的项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。</p><blockquote><p>如果使用的是 <code>MySQL</code> 的读写分离的架构的话，那么其实主从同步之间也会有时间差。</p></blockquote><p><img src="http://blog-img.coolsen.cn/img/1735bb5881bbb1d4~tplv-t2oaga2asx-watermark.awebp" alt="主从同步时间差"></p><p>此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作）</p><ol><li>请求 A 更新操作，删除了 <code>Redis</code></li><li>请求主库进行更新操作，主库与从库进行同步数据的操作</li><li>请求 B 查询操作，发现 <code>Redis</code>中没有数据</li><li>去从库中拿去数据</li><li>此时同步数据还未完成，拿到的数据是旧数据</li></ol><p>此时的解决办法就是如果是对 <code>Redis</code>缓存进行数据填充的查询数据库操作，那么就强制将其指向主库进行查询。</p><p><img src="http://blog-img.coolsen.cn/img/1735bb5881a19fec~tplv-t2oaga2asx-watermark.awebp" alt="从主库中拿数据"></p><p><strong>4.先更新数据库，后删除缓存</strong></p><p>这一种情况也会出现问题，比如更新数据库成功了，但是在删除缓存的阶段出错了没有删除成功，那么此时再读取缓存的时候每次都是错误的数据了。</p><p><img src="http://blog-img.coolsen.cn/img/1735bb5881fb4a1b~tplv-t2oaga2asx-watermark.awebp" alt="先更新数据库，后删除缓存"></p><p>此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如下：</p><ol><li>请求 A 先对数据库进行更新操作</li><li>在对 <code>Redis</code>进行删除操作的时候发现报错，删除失败</li><li>此时将<code>Redis</code>的 key 作为消息体发送到消息队列中</li><li>系统接收到消息队列发送的消息后再次对 <code>Redis</code>进行删除操作</li></ol><p>但是这个方案会有一个缺点就是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的方案，我们知道对 <code>MySQL</code> 数据库更新操作后再 binlog 日志中我们都能够找到相应的操作，那么我们可以订阅 <code>MySQL</code> 数据库的 binlog 日志对缓存进行操作。</p><p><img src="http://blog-img.coolsen.cn/img/1735bb588215b298~tplv-t2oaga2asx-watermark.awebp" alt="利用订阅 binlog 删除缓存"></p><h2 id="5-Redis的缓存读写策略"><a href="#5-Redis的缓存读写策略" class="headerlink" title="5.Redis的缓存读写策略"></a>5.Redis的缓存读写策略</h2><p><a href="https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html#cache-aside-pattern-%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F">3种常用的缓存读写策略</a></p><h2 id="6-Redis缓存问题"><a href="#6-Redis缓存问题" class="headerlink" title="6.Redis缓存问题"></a>6.Redis缓存问题</h2><ol><li><p><strong>缓存穿透：</strong>缓存中和数据库中都没有所查询的东西，从而使数据库崩掉。<br><img src="http://blog-img.coolsen.cn/img/2021013117512340.png" alt="缓存穿透"></p><ul><li>对无效的key进行缓存，如果一个查询为空，我们仍然把这个空结果进行缓存，但设置较短的过期时间。</li><li>使用布隆过滤器：用于检索一个数据是否存在</li></ul><blockquote><p>如何选择：针对一些恶意攻击，攻击带过来的大量key是随机，那么我们采用第一种方案就会缓存大量不存在key的数据。那么这种方案就不合适了，我们可以先对使用布隆过滤器方案进行过滤掉这些key。所以，针对这种key异常多、请求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，则可优先采用第一种方式进行缓存。</p></blockquote></li><li><p><strong>缓存击穿：</strong>是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。(热key)</p><ul><li>预先设置热门数据</li><li>使用锁。通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。</li></ul></li><li><p><strong>缓存雪崩：</strong>如果缓在某一个时刻出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。(多个key)</p><p>1.事前</p><ul><li>构建多级缓存架构。</li><li>设置过期标志失效更新：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。可以设置redis缓存过期监听事件。</li><li>设置不同的失效时间。如把每个Key的失效时间都加个随机值，<code>setRedis(Key, value, time + Math.random() * 10000)</code>，保证数据不会在同一时间大面积失效。</li><li>保证<code>Redis</code>缓存的高可用，防止<code>Redis</code>宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，<code>Redis</code>集群来避免 <code>Redis</code>全盘崩溃的情况。</li></ul><p>2.事中</p><ul><li>互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。</li><li>使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。</li></ul><p>3.事后</p><ul><li>开启<code>Redis</code>持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。</li></ul></li></ol><h2 id="7-Redis缓存预热与缓存降级"><a href="#7-Redis缓存预热与缓存降级" class="headerlink" title="7.Redis缓存预热与缓存降级"></a>7.Redis缓存预热与缓存降级</h2><p>1、<strong>缓存预热</strong>是指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。</p><p>如果不进行预热，那么<code>Redis</code>初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。</p><p>缓存预热解决方案：</p><ul><li><p>数据量不大的时候，工程启动的时候进行加载缓存动作；</p></li><li><p>数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；</p></li><li><p>数据量太大的时候，优先保证热点数据进行提前加载到缓存。</p></li></ul><p>2、<strong>缓存降级</strong>是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。</p><p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p><ul><li><p>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p></li><li><p>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p></li><li><p>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p></li><li><p>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://github.com/cosen1024/Java-Interview">https://github.com/cosen1024/Java-Interview</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL-索引</title>
      <link href="/2022/05/10/MySQL-%E7%B4%A2%E5%BC%95/"/>
      <url>/2022/05/10/MySQL-%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL-索引"><a href="#MySQL-索引" class="headerlink" title="MySQL-索引"></a>MySQL-索引</h1><h2 id="1-什么是索引？有哪些优缺点？"><a href="#1-什么是索引？有哪些优缺点？" class="headerlink" title="1.什么是索引？有哪些优缺点？"></a>1.什么是索引？有哪些优缺点？</h2><ol><li>索引是<strong>一个排好序的数据结构</strong>，可以提高数据库的查询效率。更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。此外，索引是一个文件，它是要占据物理空间的。<code>InnoDB</code>数据表上的索引是表空间的一个组成部分，它们包含着对数据表里所有记录的引用指针。</li><li><strong>索引的优点</strong><ul><li>大大加快数据的检索速度</li></ul></li><li><strong>索引的缺点</strong><ul><li>时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增、删、改的执行效率；</li><li>空间方面：索引需要占物理空间。</li></ul></li></ol><h2 id="2-索引的底层数据结构"><a href="#2-索引的底层数据结构" class="headerlink" title="2.索引的底层数据结构"></a>2.索引的底层数据结构</h2><ul><li><strong>Hash索引</strong></li></ul><p>基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会针对所有的索引列计算一个哈希码，并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。</p><p><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fs4.51cto.com%2Foss%2F201711%2F14%2F02ac449e68d75a8c278f538a22b57a8e.jpeg&refer=http%3A%2F%2Fs4.51cto.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1654836183&t=ee9990abd26084170178860ca5611806" alt="Hash索引示意图"></p><p><strong>优点：</strong>可以快速定位。</p><p><strong>缺点：</strong>每次IO只能取一个数，无法进行范围查找。</p><ul><li><strong>二叉查找树</strong></li></ul><p><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg-blog.csdnimg.cn%2F20210520160443363.gif&refer=http%3A%2F%2Fimg-blog.csdnimg.cn&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1654765630&t=cb160757d0e61be34ac56bdd62ef7fd1" alt="二叉搜索树"></p><p><strong>优点：</strong>拥有不错的查找性能，可以进行范围查找。</p><p><strong>缺点：</strong>在极端情况下会退化成线性链表，不平衡。</p><ul><li><strong>红黑树</strong></li></ul><p><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fupload-images.jianshu.io%2Fupload_images%2F11866517-b1bd8d323e85888a.png&refer=http%3A%2F%2Fupload-images.jianshu.io&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1654765763&t=47876328f6784b35bfec85970f2912a9" alt="红黑树"></p><p><strong>优点：</strong>拥有不错的查找性能，可以进行范围查找，可以实现平衡。</p><p><strong>缺点：</strong>在大量数据的情况下，需要较多的IO操作次数。</p><blockquote><p><strong>注：</strong>（1）MySQL查询数据的瓶颈在于磁盘IO。磁盘 IO 有个有个特点，从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的；<br>（2）计算机内存加载数据过程：寻道(确定要读的数据在哪个磁道)、旋转延迟(确定要读的数据在磁道上的哪个扇区)、数据传输(数据加载到内存)</p></blockquote><ul><li><strong>B树索引</strong></li></ul><p>B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。但是，B树每个节点内存储的是数据，因此每个节点存储的分支太少，仍然会出现IO次数较多的问题。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210411215023820.png" alt="B树索引"></p><ul><li><strong>B+树索引(MySQL默认)</strong></li></ul><p>B+树节点存储的是索引+指针(引用指向下一个节点)，同时最终数据存储在叶子节点，并且有引用横向链接。B+树成为MySQL默认使用的索引数据结构原因如下：</p><ol><li><strong>B+树的磁盘读写代价更低</strong>：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对<strong>IO读写次数就降低</strong>了。</li><li>由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在<strong>区间查询</strong>的情况，所以通常B+树用于数据库索引。</li></ol><p><img src="http://blog-img.coolsen.cn/img/image-20210411215044332.png" alt="B+树索引"></p><blockquote><p>在MySQL中，B+树的一个节点大小为一页，也就是16K。非叶子节点存储的是索引+指针；叶子节点存放的是数据行。对于叶子节点，如果一行数据大小为1k，那么一页就能存16条数据；对于非叶子节点，如果key使用的是bigint，则为8字节，指针在mysql中为6字节，一共是14字节，则16k能存放 16 * 1024 &#x2F; 14 &#x3D; 1170 个索引指针。那么高度为3的B+树就能存储上千万条数据。</p></blockquote><h2 id="3-MySQL索引的种类"><a href="#3-MySQL索引的种类" class="headerlink" title="3.MySQL索引的种类"></a>3.MySQL索引的种类</h2><h3 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h3><ol><li>非聚集索引：数据和索引分开放在一个文件里；一个表可以存在多个；逻辑上的连续，物理存储并不连续(<code>MyIsam</code>)</li><li>聚集索引：数据和索引放在同一个文件里；一个表只能有一个；存储记录是物理上连续存在(<code>InnoDB</code>)<ul><li>建表的时候 <code>InnoDB</code>就会自动建立好主键 ID 索引树。当我们为表里某个字段(e.g name)加索引时，<code>InnoDB</code>就会建立name索引B+树，叶子节点存储的数据是主键key。&#x3D;&#x3D;&gt;这样可以节省存储空间。</li><li>B+树为了维护索引有序性，再插入删除的时候需要做维护，可能涉及<strong>页分裂</strong>和<strong>页合并</strong>的过程，因为每个叶子节点存储的数据行是有限个的。&#x3D;&#x3D;&gt; 因此官方建议使用自增长主键作为索引。<br><img src="http://blog-img.coolsen.cn/img/java10-1562726251.gif" alt="插入连续的数据"><br><img src="http://blog-img.coolsen.cn/img/java8-1562726251.gif" alt="插入非连续的数据"></li></ul></li></ol><h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h3><ul><li><strong>普通索引：</strong>仅加速查询</li><li><strong>唯一索引：</strong>加速查询 + 列值唯一（可以有null）</li><li><strong>主键索引：</strong>加速查询 + 列值唯一（不可以有null）+ 表中只有一个</li><li><strong>联合索引：</strong>多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。用<strong>二分查找</strong>算法。<ul><li>全值匹配：需要遵循最左前缀原则，中间不可中断。</li><li>范围查询<ul><li>&lt;&#x3D;,&gt;&#x3D;,&gt;,&lt;的查询：1、数据量少；2、联合索引的第二个字段及更后面的字段使用；3、查询的范围值排在很后面，例如&gt;’zzz’或者&lt;’aaa’。</li><li>like的查询：需要符合最左前缀匹配原则，即%在后面的时候。这里会使用到索引下推。</li><li>in&#x2F;or的查询：对于是否使用索引查询是不确定的，mysql会结合<strong>数据量</strong>各方面因素分析确认是否要走索引的。数据量多走二级索引可以过滤掉大部分数据，回表时效率比全表扫描要快。</li></ul></li></ul></li><li><strong>全文索引：</strong>对文本的内容进行分词，进行搜索</li><li><strong>覆盖索引：</strong><code>select</code>的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖。这样可以避免对<code>InnoDB</code>主键索引的二次查询；可以优化缓存，减少磁盘IO操作。</li></ul><h2 id="4-什么是回表？"><a href="#4-什么是回表？" class="headerlink" title="4.什么是回表？"></a>4.什么是回表？</h2><p><strong>回表</strong>：二级索引树找到主键<code>id</code>后，回到<code>id</code>主键索引树搜索非索引列的过程,就称为回表。即回表需要先定位主键值，再定位行记录。</p><p><img src="https://pic4.zhimg.com/80/v2-4387a4ecf0521129d41b4172c710e04b_720w.jpg" alt="回表"></p><p><strong>如何判断何时需要进行回表查询？</strong></p><p>这涉及到查询语句所要查询的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为”覆盖索引”。</p><h2 id="5-最左前缀原则"><a href="#5-最左前缀原则" class="headerlink" title="5.最左前缀原则"></a>5.最左前缀原则</h2><p><strong>最左前缀原则</strong>：就是最左优先，在检索数据时从联合索引的最左边开始匹配。</p><p><code>MySQL</code>会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p><blockquote><p><code>MySQL</code>使用索引时需要索引有序，假设现在建立了(name, age, school)的联合索引，那么索引的排序为：先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。</p><p>当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p></blockquote><p>若所有的索引都使用&#x3D;和in，则该联合索引(a,b,c,d)可以乱序，比如a &#x3D; 1 and b &#x3D; 2 and d &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序，<code>MySQL</code>的查询优化器会帮你优化成索引可以识别的形式。</p><h2 id="6-前缀索引"><a href="#6-前缀索引" class="headerlink" title="6. 前缀索引"></a>6. 前缀索引</h2><p>因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 。</p><p>流程是： </p><p> 先计算完整列的选择性 :<code> select count(distinct col_1)/count(1) from table_1 </code></p><p> 再计算不同前缀长度的选择性 :<code>select count(distinct left(col_1,4))/count(1) from table_1 </code></p><p> 找到最优长度之后，创建前缀索引 :<code> create index idx_front on table_1 (col_1(4))</code></p><h2 id="7-索引下推"><a href="#7-索引下推" class="headerlink" title="7.索引下推"></a>7.索引下推</h2><p><strong>索引下推</strong>（Index Condition Pushdown，ICP）在<strong>非主键索引</strong>上的优化，可以有效减少回表的次数，大大提升了查询的效率。</p><img src="/2022/05/10/MySQL-%E7%B4%A2%E5%BC%95/ICP.png" class="" title="索引下推例子"><p><a href="https://zhuanlan.zhihu.com/p/419127733">索引下推讲解</a></p><h2 id="8-如何创建索引？"><a href="#8-如何创建索引？" class="headerlink" title="8. 如何创建索引？"></a>8. 如何创建索引？</h2><p>创建索引有三种方式。</p><p><strong>1、 在执行CREATE TABLE时创建索引</strong></p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> user_index2 <span class="token punctuation">(</span>    id <span class="token keyword">INT</span> <span class="token keyword">auto_increment</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span><span class="token punctuation">,</span>    first_name <span class="token keyword">VARCHAR</span> <span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    last_name <span class="token keyword">VARCHAR</span> <span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    id_card <span class="token keyword">VARCHAR</span> <span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    information <span class="token keyword">text</span><span class="token punctuation">,</span>    <span class="token keyword">KEY</span> name <span class="token punctuation">(</span>first_name<span class="token punctuation">,</span> last_name<span class="token punctuation">)</span><span class="token punctuation">,</span>    FULLTEXT <span class="token keyword">KEY</span> <span class="token punctuation">(</span>information<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token keyword">UNIQUE</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span>id_card<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p><strong>2、 使用ALTER TABLE命令去增加索引。</strong></p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span> <span class="token keyword">INDEX</span> index_name <span class="token punctuation">(</span>column_list<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。</p><p>其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。</p><p>索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。<br><strong>3、 使用CREATE INDEX命令创建。</strong></p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> index_name <span class="token keyword">ON</span> table_name <span class="token punctuation">(</span>column_list<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h2 id="9-创建索引时需要注意什么？"><a href="#9-创建索引时需要注意什么？" class="headerlink" title="9. 创建索引时需要注意什么？"></a>9. 创建索引时需要注意什么？</h2><ol><li>非空字段：应该指定列为NOT NULL，除非你想存储NULL。在<code>mysql</code>中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</li><li>取值离散大的字段：离散程度（变量各个取值之间的差异程度）大的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；</li><li>索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。</li></ol><h2 id="10-创建索引的原则"><a href="#10-创建索引的原则" class="headerlink" title="10.创建索引的原则"></a>10.创建索引的原则</h2><ul><li><p>最左前缀匹配原则</p></li><li><p>频繁作为查询的条件的字段应该创建索引</p></li><li><p>JOIN 关联查询，作为外键关系的列创建索引</p></li><li><p>ORDER BY 查询中排序的字段创建索引</p></li><li><p>GROUP BY 需要分组字段或查询中统计count()字段</p></li><li><p>表记录太少不要创建索引</p></li><li><p>经常增删改的表不要创建索引</p></li><li><p><strong>数据重复</strong>且分布平均的表字段不要创建索引</p></li><li><p>尽量的扩展索引，不要新建索引。</p></li></ul><h2 id="11-什么情况下索引失效"><a href="#11-什么情况下索引失效" class="headerlink" title="11.什么情况下索引失效"></a>11.什么情况下索引失效</h2><ol><li>联合索引中，不遵循最佳左前缀法则会使索引失效</li><li>联合索引中，范围查询<strong>右边失效原理</strong>（针对查询条件中出现”&gt;”、”&lt;”、”&gt;&#x3D;”、”&lt;&#x3D;”的情况）。将需要”&gt;”、”&lt;”、”&gt;&#x3D;”、”&lt;&#x3D;”这种情况的查询列放在联合索引的最后面</li><li>where中对索引列上做任何操作（计算、函数、（自动or手动）类型转换）</li><li>is null,is not null 也无法使用索引</li><li>like通配符，左侧开放情况下，全表扫描</li><li>!&#x3D;，not in 不走索引（辅助索引）,但是主键&#x2F;唯一索引来说“ !&#x3D;，not in”走索引。建立辅助索引的列，不能保证其键值的唯一性</li><li>or条件筛选，如果or连接的是同一个索引字段，则生效；如果or连接的是两个不同的字段，但是两个字段都建立了索引，生效。</li></ol><blockquote><p>如果规避了上面这些情况，建立的索引就一定会生效吗？</p></blockquote><p>不一定。经过优化器的确定查询方案，依然可能索引失效。优化器会考虑查询成本，来确定它认为的最佳方案来执行查询。当数据量较少或者需要访问很多行数据的时候，优化器会认为全表扫描更快。</p><h2 id="12-如何查看MySQL语句有没有用到索引？"><a href="#12-如何查看MySQL语句有没有用到索引？" class="headerlink" title="12. 如何查看MySQL语句有没有用到索引？"></a>12. 如何查看MySQL语句有没有用到索引？</h2><p>通过explain，如以下例子：</p><p><code>EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#39;10001&#39; AND title=&#39;Senior Engineer&#39; AND from_date=&#39;1986-06-26&#39;;</code></p><table><thead><tr><th>id</th><th>select_type</th><th>table</th><th>partitions</th><th>type</th><th>possible_keys</th><th>key</th><th>key_len</th><th>ref</th><th>filtered</th><th>rows</th><th>Extra</th></tr></thead><tbody><tr><td>1</td><td>SIMPLE</td><td>titles</td><td>null</td><td>const</td><td>PRIMARY</td><td>PRIMARY</td><td>59</td><td>const,const,const</td><td>10</td><td>1</td><td></td></tr></tbody></table><ul><li><p><strong>id</strong>：在⼀个⼤的查询语句中每个<strong>SELECT</strong>关键字都对应⼀个唯⼀的id ，如explain select * from s1 where id &#x3D; (select id from s1 where name &#x3D; ‘egon1’)；第一个select的id是1，第二个select的id是2。有时候会出现两个select，但是id却都是1，这是因为优化器把子查询变成了连接查询 。</p></li><li><p><strong>select_type</strong>：select关键字对应的那个查询的类型，如SIMPLE, PRIMARY, SUBQUERY, DERIVED, UNION。</p></li><li><p><strong>table</strong>：每个查询对应的表名。</p></li><li><p><strong>type</strong>：<code>type</code> 字段比较重要, 它提供了判断查询是否高效的重要依据依据。通过 <code>type</code> 字段，我们判断此次查询是<strong>全表扫描</strong>还是<strong>索引扫描</strong>等。如<code>const</code>(主键索引或者唯一二级索引进行等值匹配的情况下)，<code>ref</code>(普通的⼆级索引列与常量进⾏等值匹配)，<code>index</code>(扫描全表索引的覆盖索引) 。</p><p>通常来说，不同的 <code>type</code> 类型的性能关系如下：</p><pre class=" language-sqlite"><code class="language-sqlite">ALL < index < range ~ index_merge < ref < eq_ref < const < system</code></pre><p><code>ALL</code> 类型因为是全表扫描，因此在相同的查询条件下，它是速度最慢的。<br>而 <code>index</code> 类型的查询虽然不是全表扫描，但是它扫描了所有的索引，因此比<code>ALL</code>类型的稍快.</p></li><li><p><strong>possible_key</strong>：查询中可能用到的索引*(可以把用不到的删掉，降低优化器的优化时间)* 。</p></li><li><p><strong>key</strong>：此字段是<code>MySQL</code>在当前查询时所真正使用到的索引。</p></li><li><p><strong>filtered</strong>：查询器预测满足下一次查询条件的百分比 。</p></li><li><p><strong>rows</strong> ：<code>MySQL</code>查询优化器根据统计信息，估算<code>SQL</code>要查找到结果集需要扫描读取的数据行数。<br>这个值非常直观显示<code>SQL</code>的效率好坏，原则上<code>rows</code>越少越好。</p></li><li><p><strong>extra</strong>：表示额外信息，如Using where, Start temporary, End temporary, Using temporary等。</p></li></ul><blockquote><p>使用索引查询一定能提高查询的性能吗？</p></blockquote><p>通常通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。</p><p>索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I&#x2F;O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:</p><ul><li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%。</li><li>基于非唯一性索引的检索。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://github.com/cosen1024/Java-Interview">https://github.com/cosen1024/Java-Interview</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis-介绍</title>
      <link href="/2022/05/09/Redis-%E4%BB%8B%E7%BB%8D/"/>
      <url>/2022/05/09/Redis-%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是Redis？"><a href="#1-什么是Redis？" class="headerlink" title="1.什么是Redis？"></a>1.什么是Redis？</h2><p><code>Redis</code>又称远程字典服务，是一个key-value数据库，通过将数据缓存在内存中，提高效率。</p><p><strong>优点</strong>：</p><ul><li>读写性能极高，<code>Redis</code>读的速度是110000次&#x2F;s，写的速度是81000次&#x2F;s。</li><li>支持数据持久化，支持<code>AOF</code>和<code>RDB</code>两种持久化方式。</li><li>支持事务， <code>Redis</code>的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过<code>MULTI</code>和<code>EXEC</code>指令包起来。</li><li>数据结构丰富，除了支持string类型的value外，还支持hash、set、zset、list等数据结构。</li><li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li><li>丰富的特性 – <code>Redis</code>还支持 <code>publish/subscribe</code>、通知、key 过期等特性。</li></ul><p><strong>缺点</strong>：</p><ul><li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</li><li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</li></ul><h2 id="2-Redis速度为什么快？"><a href="#2-Redis速度为什么快？" class="headerlink" title="2.Redis速度为什么快？"></a>2.Redis速度为什么快？</h2><ul><li><p><strong>内存存储</strong>：<code>Redis</code>是使用内存存储，没有磁盘IO上的开销。数据存在内存中，类似于 <code>HashMap</code>，<code>HashMap</code> 的优势就是查找和操作的时间复杂度都是O(1)。</p></li><li><p><strong>单线程实现</strong>（ Redis 6.0以前）：<code>Redis</code>使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销。注意：单线程是指的是在核心网络模型中，网络请求模块使用一个线程来处理，即一个线程处理所有网络请求。</p></li><li><p><strong>非阻塞IO</strong>：<code>Redis</code>使用多路复用IO技术，将<code>epoll</code>作为I&#x2F;O多路复用技术的实现，再加上Redis自身的事件处理模型将<code>epoll</code>中的连接、读写、关闭都转换为事件，不在网络I&#x2F;O上浪费过多的时间。</p></li><li><p><strong>优化的数据结构</strong>：<code>Redis</code>有诸多可以直接应用的优化数据结构的实现，应用层可以直接使用原生的数据结构提升性能。</p></li><li><p><strong>使用底层模型不同</strong>：<code>Redis</code>直接自己构建了虚拟内存<code>VM </code>机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p></li></ul><blockquote><p><code>Redis</code>的虚拟内存<code>VM</code>机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过<code>VM</code>功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。</p><p><code>Redis</code>提高数据库容量的办法有两种：一种是可以将数据分割到多个<code>Redis</code>服务器上；另一种是使用虚拟内存把那些不经常访问的数据交换到磁盘上。<strong>需要特别注意的是Redis并没有使用OS提供的Swap，而是自己实现。</strong></p></blockquote><h2 id="3-Redis相比Memcached有哪些优势？"><a href="#3-Redis相比Memcached有哪些优势？" class="headerlink" title="3. Redis相比Memcached有哪些优势？"></a>3. Redis相比Memcached有哪些优势？</h2><ul><li><p><strong>数据类型</strong>：<code>Memcached</code>所有的值均是简单的字符串，<code>Redis</code>支持更为丰富的数据类型，支持String(字符串)，List(列表)，Set(集合)、ZSet(有序集合)、Hash(哈希)等。</p></li><li><p><strong>持久化</strong>：<code>Redis</code>支持数据持久化存储，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 <code>Memcached</code>不支持数据持久存储。</p></li><li><p><strong>集群模式</strong>：<code>Redis</code>提供主从同步机制，以及集群部署能力，能够提供高可用服务。<code>Memcached</code>没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p></li><li><p><strong>网络IO模型</strong>：<code>Redis</code>使用单线程的多路 IO 复用模型，<code>Memcached</code>使用多线程的非阻塞IO模式。</p></li><li><p>Redis支持服务器端的数据操作：<code>Redis</code>相比<code>Memcached</code>来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在<code>Memcached</code>里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在<code>Redis</code>中，这些复杂的操作通常和一般的GET&#x2F;SET一样高效。</p></li></ul><h2 id="4-为什么要用-Redis-做缓存？"><a href="#4-为什么要用-Redis-做缓存？" class="headerlink" title="4. 为什么要用 Redis 做缓存？"></a>4. 为什么要用 Redis 做缓存？</h2><p>1、<strong>从高并发上来说：</strong></p><p>​直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</p><p>2、<strong>从高性能上来说：</strong></p><p>​用户第一次访问数据库中的某些数据。 因为是从硬盘上读取的所以这个过程会比较慢。将该用户访问的数据存在缓存中，下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据。</p><h2 id="5-Redis的数据类型"><a href="#5-Redis的数据类型" class="headerlink" title="5.Redis的数据类型"></a>5.Redis的数据类型</h2><ol><li><p><code>string</code>：每个字符串都是simple dynamic string，采用预分配冗余空间的方式来减少内存的频繁分配。SDS由三个部分组成：<code>free</code>:还剩多少空间 ;<code>len</code>:字符串长度 ;<code>buf</code>:存放的字符数组 </p></li><li><p><code>list</code>：简单的字符串列表(单键多值)，按照插入顺序排序，实际是个双向链表。</p><ul><li>List在元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist(压缩列表)；当数据量较多时使用quicklist(链表+压缩列表)，这样既满足了快速插入删除性能，又能避免出现太大的空间冗余。</li><li>压缩列表(ziplist)：所有元素紧挨存储在一起，分配的是一块连续的内存，用于<strong>存储小整数值，或者长度比较短的字符串</strong>。可以双向遍历(在数据结构中保存到最后一个元素的偏移量)，每个元素的长度不一定都相等。</li></ul></li><li><p><code>set</code>：对外提供的功能与list类似，也是一个列表，但提供自动去重的功能。</p><ul><li>底层数据结构：<ul><li>intset(可以理解为数组)：元素个数不少于512；元素可以用整形表示。查询方式用二分查找。</li><li>dict：key为set中元素的值，而value为null。</li></ul></li></ul></li><li><p><code>hash</code>：是一个键值对集合，类似于Java中的Map&lt;String, Object&gt;</p><ul><li>数据结构：<ul><li>ziplist(压缩列表)：hash对象保存的键和值字符串长度都小于64字节；hash对象保存的键值对数量小于512。</li><li>dict：由hashtable组成，可以动态扩容、缩容。</li></ul></li><li><strong>hash扩容、缩容</strong>：通过<code>ht</code>(包含了两个项的数组)和<code>rehashindex</code>(表示rehash目前的进度，如果没有进行rehash，则为-1)，目的是为了让hash负载因子维持在一个合理的范围。<ul><li>rehash 动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。避免庞大的计算量导致服务器在一段时间内停止服务。<strong>渐进式rehash</strong>过程如下：1、为ht[1]分配空间，并将rehashindex的值设置为0，表示rehash工作正式开始；2、在rehash期间，每次对字典执行增删改查操作，除了执行指定的操作以外，还会顺带将ht[0]在rehashindex索引下的所有键值对rehash到ht[1]，当前rehash过程结束后，将rehashindex+1；3、随着字典操作的不断进行，最终在某个时间点，ht[0]上的所有键值对都被rehash到ht[1]，这时将rehashindex设置为-1，表示rehash整个过程完成。</li><li><strong>注：</strong>在渐进式rehash的过程中，字典会同时使用ht[0]、ht[1]两个哈希表。在查找过程中，先在ht[0]上进行，如果没有找到再去ht[1]上进行；添加过程一律保存到ht[1]上，保证ht[0]包含的键值对只会减少不会增加。</li></ul></li></ul></li><li><p><code>zset</code>：有序集合的每个成员都关联了一个评分（score），这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。（zset可以用于构建<strong>延时队列</strong>）</p><ul><li><p>数据结构：</p><ul><li>ziplist(压缩列表)：hash对象保存的键和值字符串长度都小于64字节；hash对象保存的键值对数量小于128。<br><strong>存储方式</strong>：每个集合元素使用两个相邻的压缩列表节点存储                                                                                                                                              ，一个保存元素的成员，一个保存元素的分值。</li><li>dict+跳跃表<br><strong>存储方式</strong>：<strong>dict存储元素key和value，用于关联value和score；跳跃表：节点包含*obj指针指向key，用于给元素value排序</strong>，比有序链表效率高。redis的索引被提取为多层，所有的元素都会在L0层的链表中，根据分数对value进行排序，同时有一部分节点有机会被抽取到L1层，作为一个稀疏链表。同时L1层的一部分节点也有机会被抽取到L2层中，组成一个更稀疏的索引链表。从最高等级向低等级查询，类似于二分查找。</li></ul></li><li><p>应用：score存储时间戳。生产者生产消息时，用当前时间戳加上延时的时间戳；消费者拉取消息的时候，截取zset满足当前时间的数据，消费完移除消息。</p></li></ul></li></ol><p><strong>三种特殊的数据类型</strong>：</p><ol><li><code>Bitmap</code>：位图，Bitmap想象成一个以位为单位数组，数组中的每个单元只能存0或者1，数组的下标在Bitmap中叫做偏移量。使用Bitmap实现统计功能，更省空间。如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。</li><li><code>Hyperloglog</code>：HyperLogLog 是一种用于统计基数的数据集合类型，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。场景：统计网页的UV（即Unique Visitor，不重复访客，一个人访问某个网站多次，但是还是只计算为一次）。要注意，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。</li><li><code>Geospatial</code>：主要用于存储地理位置信息，并对存储的信息进行操作，适用场景如朋友的定位、附近的人、打车距离计算等。</li></ol><h2 id="6-Redis的常用场景有哪些"><a href="#6-Redis的常用场景有哪些" class="headerlink" title="6. Redis的常用场景有哪些?"></a>6. Redis的常用场景有哪些?</h2><p><strong>1、缓存</strong></p><p>缓存现在几乎是所有中大型网站都在用的必杀技，合理的利用缓存不仅能够提升网站访问速度，还能大大降低数据库的压力。<code>Redis</code>提供了键过期功能，也提供了灵活的键淘汰策略，所以，现在<code>Redis</code>用在缓存的场合非常多。</p><p><strong>2、排行榜</strong></p><p>很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜等。<code>Redis</code>提供的有序集合<code>zset</code>数据类构能实现各种复杂的排行榜应用。</p><p><strong>3、计数器</strong></p><p>什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是种挑战和压力。<code>Redis</code>提供的incr命令来实现计数器功能，内存操作，性能非常好，非常适用于这些计数场景。</p><p><strong>4、分布式会话</strong></p><p>集群模式下，在应用不多的情况下一般使用容器自带的session复制功能就能满足，当应用增多相对复杂的系统中，一般都会搭建以<code>Redis</code>等内存数据库为中心的session服务，session不再由容器管理，而是由session服务及内存数据库管理。</p><p><strong>5、分布式锁</strong></p><p>在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如全局ID、减库存、秒杀等场景，并发量不大的场景可以使用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用<code>Redis</code>的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败，实际应用中要考虑的细节要更多。</p><p><strong>6、 社交网络</strong></p><p>点赞、踩、关注&#x2F;被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis提供的哈希<code>hash</code>、集合<code>set</code>等数据结构能很方便的的实现这些功能。如在微博中的共同好友，通过Redis的set能够很方便得出。</p><p><strong>7、最新列表</strong></p><p>Redis列表结构<code>list</code>，LPUSH可以在列表头部插入一个内容ID作为关键字，LTRIM可用来限制列表的数量，这样列表永远为N个ID，无需查询最新的列表，直接根据ID去到对应的内容页即可。</p><p><strong>8、消息系统</strong></p><p>消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布&#x2F;订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个不能和专业的消息中间件相比。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://github.com/cosen1024/Java-Interview">https://github.com/cosen1024/Java-Interview</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL-锁</title>
      <link href="/2022/05/09/MySQL-%E9%94%81/"/>
      <url>/2022/05/09/MySQL-%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL-锁"><a href="#MySQL-锁" class="headerlink" title="MySQL-锁"></a>MySQL-锁</h1><h2 id="1-为什么要加锁？"><a href="#1-为什么要加锁？" class="headerlink" title="1.为什么要加锁？"></a>1.为什么要加锁？</h2><p>当多个用户并发地存取数据时，在数据库中就可能出现多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。所以数据库加锁是为了<strong>保证多用户环境下保证数据库完整性和一致性。</strong></p><h2 id="2-数据库锁都有哪些？"><a href="#2-数据库锁都有哪些？" class="headerlink" title="2.数据库锁都有哪些？"></a>2.数据库锁都有哪些？</h2><h3 id="1-按照锁的粒度"><a href="#1-按照锁的粒度" class="headerlink" title="1.按照锁的粒度"></a>1.按照锁的粒度</h3><p>对数据操作的粒度大小</p><p><strong>行级锁</strong></p><ul><li>行级锁是<code>MySQL</code>中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。</li><li>开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</li></ul><p><strong>表级锁</strong></p><ul><li>表级锁是<code>MySQL</code>中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分<code>MySQL</code>引擎支持。最常使用的<code>MYISAM</code>与<code>INNODB</code>都支持表级锁定。</li><li>开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</li></ul><p><strong>页级锁</strong></p><ul><li>页级锁是<code>MySQL</code>中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。<code>BDB</code>支持页级锁。</li><li>开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</li></ul><p><strong>MyISAM和InnoDB存储引擎使用的锁：</strong></p><ul><li><code>MyISAM</code>采用表级锁(table-level locking)。</li><li><code>InnoDB</code>支持行级锁(row-level locking)和表级锁，默认为行级锁</li></ul><h3 id="2-按照锁的类别"><a href="#2-按照锁的类别" class="headerlink" title="2.按照锁的类别"></a>2.按照锁的类别</h3><ul><li><p>共享锁：又叫做读锁。当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p></li><li><p>排他锁：又叫做写锁。当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p></li></ul><h2 id="3-数据库的乐观锁和悲观锁"><a href="#3-数据库的乐观锁和悲观锁" class="headerlink" title="3.数据库的乐观锁和悲观锁"></a>3.数据库的乐观锁和悲观锁</h2><p>数据库管理系统<code>DBMS</code>中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</p><ol><li>悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制。<ul><li>适合写多读少的场景。</li></ul></li><li>乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过<code>version</code>的方式来进行锁定。实现方式：<code>version</code>版本字段或者<code>timestamp</code>时间戳字段机制+<code>CAS</code>算法实现。<ul><li>适合读多写少的场景。</li></ul></li></ol><h2 id="4-InnoDB引擎的行锁是怎么实现的？"><a href="#4-InnoDB引擎的行锁是怎么实现的？" class="headerlink" title="4.InnoDB引擎的行锁是怎么实现的？"></a>4.InnoDB引擎的行锁是怎么实现的？</h2><p><code>InnoDB</code>是基于索引来完成行锁例：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> tab_with_index <span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">for</span> <span class="token keyword">update</span><span class="token punctuation">;</span></code></pre><p><code>for update</code> 可以根据条件来完成行锁锁定，并且<code>id</code>是有索引键的列，如果 <code>id </code>不是索引键那么<code>InnoDB</code>将完成表锁，并发将无从谈起。</p><h2 id="5-什么是死锁？怎么解决？"><a href="#5-什么是死锁？怎么解决？" class="headerlink" title="5. 什么是死锁？怎么解决？"></a>5. 什么是死锁？怎么解决？</h2><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。死锁的关键在于：<strong>两个(或以上)的事务加锁的顺序不一致</strong>。</p><p>常见的解决死锁的方法</p><p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p><p>2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p><p>3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p><p>如果业务处理不好可以用分布式事务锁或者使用乐观锁</p><h2 id="6-隔离级别与锁的关系"><a href="#6-隔离级别与锁的关系" class="headerlink" title="6. 隔离级别与锁的关系"></a>6. 隔离级别与锁的关系</h2><ul><li>在<code>Read Uncommitted</code>级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突</li><li>在<code>Read Committed</code>级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；</li><li>在<code>Repeatable Read</code>级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。</li><li><code>SERIALIZABLE </code>是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。</li></ul><h2 id="7-优化锁方面的意见？"><a href="#7-优化锁方面的意见？" class="headerlink" title="7. 优化锁方面的意见？"></a>7. 优化锁方面的意见？</h2><ul><li>使用较低的隔离级别</li><li>设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突</li><li>选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。例如，修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁</li><li>不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。</li><li>尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响</li><li>不要申请超过实际需要的锁级别</li><li>数据查询的时候不是必要，不要使用加锁。<code>MySQL</code>的<code>MVCC</code>可以实现事务中的查询不用加锁，优化事务性能：<code>MVCC</code>只在<code>committed read</code>（读提交）和<code>repeatable read</code>（可重复读）两种隔离级别</li><li>对于特定的事务，可以使用表锁来提高处理速度以及减少死锁的可能。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://github.com/cosen1024/Java-Interview">https://github.com/cosen1024/Java-Interview</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL-事务</title>
      <link href="/2022/05/05/MySQL-%E4%BA%8B%E5%8A%A1/"/>
      <url>/2022/05/05/MySQL-%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL事务及其特征"><a href="#MySQL事务及其特征" class="headerlink" title="MySQL事务及其特征"></a>MySQL事务及其特征</h2><ol><li><strong>事务</strong>是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。</li><li>事务的四个特征<ul><li><strong>原子性</strong>(Atomicity)：事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做。</li><li><strong>一致性</strong>(Consistency)：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。</li><li><strong>隔离性</strong>(Isolation)：一个事务的执行不能被其它事务干扰。即一个事务内部的操作对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。</li><li><strong>持续性</strong>(Durability)：一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。</li></ul></li></ol><h2 id="MySQL四种隔离级别"><a href="#MySQL四种隔离级别" class="headerlink" title="MySQL四种隔离级别"></a>MySQL四种隔离级别</h2><ul><li><strong>脏读</strong>：一个事务读取另一个事务还未提交的数据。事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。</li><li><strong>不可重复读</strong>：一个事务内多次读同一数据，在这个事务还没结束时，另一个事务修改该数据。事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。</li><li><strong>幻读</strong>：一个事务内多次读同一数据，在这个事务还没结束时，另一个事务插入了一些数据。这就导致事务前后查询出的记录数目不一致，就好像发生了幻觉一样，这就叫幻读。</li></ul><h3 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h3><ol><li><code>Read Uncommitted</code>（读未提交）：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。</li><li><code>Read Committed</code>（读已提交）：一个事务只能看见已经提交事务所做的改变。</li><li><code>Repeatable Read</code>（可重复读）：它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。这是 MySQL 的默认事务隔离级别。</li><li><code>Serializable</code>（可串行化）：通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。</li></ol><p><img src="http://blog-img.coolsen.cn/img/image-20210822180308501.png" alt="四种隔离级别"></p><p>MySQL 默认采用的 REPEATABLE_READ隔离级别， Oracle 默认采用的 READ_COMMITTED隔离级别</p><p>事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p><p>因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读已提交)；但是你要知道的是InnoDB 存储引擎默认使用 <strong>REPEATABLE-READ（可重读）</strong>并不会有任何性能损失。</p><p>InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。</p><h2 id="MySQL事务日志"><a href="#MySQL事务日志" class="headerlink" title="MySQL事务日志"></a>MySQL事务日志</h2><p>事务是基于重做日志(<code>redo log</code>)和回滚日志(<code>undo log</code>)实现的。</p><ul><li><code>redo log</code>：每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过<strong>重做日志来保证事务的原子性和持久性。</strong></li><li><code>undo log</code>：每当有修改事务时，会产生回滚日志，如果需要回滚，则根据回滚日志的反向语句进行逻辑操作。比如 insert 一条记录就产生一条delete记录。<strong>回滚日志主要实现数据库的一致性。</strong></li></ul><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p><code>redo log</code>（重做日志）是<code>InnoDB</code>存储引擎独有的，它让<code>MySQL</code>拥有了崩溃恢复能力。</p><p><code>redo log</code>在事务的执行过程中，便开始写入<code>redo log buffer</code>，接着刷盘到<code>redo log</code>文件里面 。硬盘上存储的 <code>redo log</code> 日志文件不只一个，而是以一个<strong>日志文件组</strong>的形式出现的，每个的<code>redo</code>日志文件大小都是一样的。</p><blockquote><p>注：每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成</p></blockquote><p><img src="http://blog-img.coolsen.cn/img/image-20210822181340692.png" alt="redo log"></p><h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3><p><code>undo log</code> 用来回滚行记录到某个版本。事务未提交之前，回滚日志保存了未提交之前的版本数据，回滚日志中的数据可作为数据旧版本快照供其他并发事务进行快照读。在 MySQL innodb 存储引擎中用<code>undo log</code>实现多版本并发控制。</p><p><img src="http://blog-img.coolsen.cn/img/image-20210822181416382.png" alt="undo log"></p><h2 id="MySQL的binlog"><a href="#MySQL的binlog" class="headerlink" title="MySQL的binlog"></a>MySQL的binlog</h2><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/01.png" alt="binlog"></p><p><code>binlog</code>(归档日志)是server层的，无论MySQL用什么引擎都会有的，主要是用作主从复制，时间点恢复。归档日志是记录所有数据库表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。归档日志不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，但可以通过查询通用日志来查看 MySQL 执行过的所有语句。</p><h3 id="记录格式"><a href="#记录格式" class="headerlink" title="记录格式"></a>记录格式</h3><ul><li><p><strong>statement：</strong> 基于 SQL 语句的模式，某些语句和函数如<code>update_time=now()</code>在复制过程可能导致数据不一致甚至出错。</p></li><li><p><strong>row：</strong> 基于行的模式，记录的是行的变化，很安全。但是<code>binlog</code>会比其他两种模式大很多，在一些大表中清除大量数据时在<code>binlog</code>中会生成很多条语句，可能导致从库延迟变大。</p></li><li><p><strong>mixed：</strong> 混合模式，根据语句来选用是 statement 还是 row 模式。</p></li></ul><h3 id="写入机制"><a href="#写入机制" class="headerlink" title="写入机制"></a>写入机制</h3><p><code>binlog</code>的写入时机也非常简单，事务执行过程中，先把日志写到<code>binlog cache</code>，事务提交的时候，再把<code>binlog cache</code>写到<code>binlog</code>文件中。</p><p>因为一个事务的<code>binlog</code>不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为<code>binlog cache</code>。</p><p>我们可以通过<code>binlog_cache_size</code>参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（<code>Swap</code>）。</p><p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/04-20220305234747840.png" alt="binlog写入机制"></p><h2 id="MVCC的实现原理"><a href="#MVCC的实现原理" class="headerlink" title="MVCC的实现原理"></a>MVCC的实现原理</h2><p><code>MVCC</code>， 即多版本并发控制。<code>MVCC</code> 的实现，是通过保存数据在某个时间点的快照来实现的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p><p><code>MVCC</code>实现：</p><ul><li><strong>隐藏字段</strong><ul><li><code>DB_TRX_ID</code>：表示最后一次插入或更新该行的事务 id。</li><li><code>DB_ROLL_PTR</code>：指向该行的 <code>undo log</code>。</li></ul></li><li><strong>Read View</strong>：主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”<br>创建一个新事务后，执行每个 <code>select</code> 语句前，都会创建一个快照（<code>Read View</code>），<strong>快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号</strong>。</li><li><strong>undo log</strong>：当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 <code>undo log</code> 读取之前的版本数据，以此实现非锁定读</li></ul><p>在内部实现中，通过<code>DB_TRX_ID</code>和<code>Read View</code>来判断数据的可见性，如果不可见，则通过数据行的<code>DB_ROLL_PTR</code>找到<code>undo log</code>中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建<code>Read View</code>之前已经提交的数据和该事务中所做的修改。</p><p><img src="http://blog-img.coolsen.cn/img/modb_95751916-225c-11eb-b0bb-5254001c05fe.png" alt="mvcc原理"></p><p><code>MVCC</code> 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 <code>MVCC</code>，保证了事务 ACID 中的 I（隔离性）特性。</p><ol><li>快照读：读取的是记录的可见版本(可能是历史版本)，不用加锁<ul><li>在<code>RR</code> 和 <code>RC</code> 两个隔离级别下，简单的select操作，属于快照读</li><li>实现：通常做法是加一个版本号或者时间戳字段，在更新数据的同时版本号 + 1 或者更新时间戳。查询时，将当前可见的版本号与对应记录的版本号进行比对，如果记录的版本小于可见版本，则表示该记录可见</li></ul></li><li>当前读：读取的是记录的最新版本，并且当前读返回的记录，都会加锁，避免其他事务并发修改这条记录。<ul><li>特殊的读操作，插入&#x2F;更新&#x2F;删除操作，属于当前读</li><li>加锁的情况：<br>1、<code>select ... lock in share mode</code>：对记录加 <code>S</code> 锁，其它事务也可以加<code>S</code>锁，如果加 <code>x</code> 锁则会被阻塞。<br>2、<code>select ... for update</code>、<code>insert</code>、<code>update</code>、<code>delete</code>：对记录加 <code>X</code> 锁，且其它事务不能加任何锁</li></ul></li></ol><p>结论：在MySQL&#x2F;InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。</p><h3 id="RC-和-RR-隔离级别下-MVCC-的差异"><a href="#RC-和-RR-隔离级别下-MVCC-的差异" class="headerlink" title="RC 和 RR 隔离级别下 MVCC 的差异"></a>RC 和 RR 隔离级别下 MVCC 的差异</h3><p>在事务隔离级别 <code>RC</code> 和 <code>RR</code> （InnoDB 存储引擎的默认事务隔离级别）下，<code>InnoDB</code> 存储引擎使用 <code>MVCC</code>（非锁定一致性读），但它们生成 <code>Read View</code> 的时机却不同</p><ul><li>在 <code>RC</code> 隔离级别下的每次<code>select</code> 查询前都生成一个<code>Read View</code> (m_ids 列表)&#x3D;&#x3D;&gt;<strong>导致不可重复读</strong><br>RC隔离级别需要保持语句级别的一致性，开销较大</li><li>在 <code>RR</code> 隔离级别下只在事务开始后 第一次<code>select</code> 查询前生成一个<code>Read View</code>（m_ids 列表）<br>RR隔离级别获得的是事务级读—致性，消耗更少</li></ul><h3 id="InnoDB如何解决幻读"><a href="#InnoDB如何解决幻读" class="headerlink" title="InnoDB如何解决幻读"></a>InnoDB如何解决幻读</h3><p><strong>1、执行普通 <code>select</code>，此时会以 <code>MVCC</code> 快照读的方式读取数据</strong></p><p>在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 <code>Read View</code> ，并使用至事务提交。所以在生成 <code>Read View</code> 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”</p><p><strong>2、执行 select…for update&#x2F;lock in share mode、insert、update、delete 等当前读</strong></p><p>在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！<code>InnoDB</code> 使用<code>Next-key Lock </code>来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。 </p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://github.com/cosen1024/Java-Interview">https://github.com/cosen1024/Java-Interview</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL-基础</title>
      <link href="/2022/05/05/MySQL-%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/05/05/MySQL-%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="数据库的三大范式"><a href="#数据库的三大范式" class="headerlink" title="数据库的三大范式"></a>数据库的三大范式</h2><ol><li><strong>第一范式</strong>：字段不可分；</li><li><strong>第二范式</strong>：有主键，非主键字段依赖主键。一个表只说明一个事务；</li><li><strong>第三范式</strong>：非主键字段不能相互依赖。每列都与主键有直接关系，不存在传递依赖。</li></ol><h2 id="MySQL支持的存储引擎"><a href="#MySQL支持的存储引擎" class="headerlink" title="MySQL支持的存储引擎"></a>MySQL支持的存储引擎</h2><p>MySQL 支持多种存储引擎，比如 InnoDB、MyISAM、Memory、Archive 等等。InnoDB 也是 MySQL 的默认存储引擎。</p><p><strong>MyIsam</strong>和<strong>InnoDB</strong>存储引擎区别</p><ol><li>InnoDB支持事务(因为undo log), MyISAM不支持</li><li>InnoDB支持行级锁， MyISAM支持表级锁</li><li>InnoDB支持多版本并发控制(<strong>MVVC</strong>)，MyISAM不支持</li><li>InnoDB支持外键，MyISAM不支持</li><li>MyISAM支持全文索引，InnoDB不支持</li><li>InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。</li></ol><h2 id="主键、超键、候选键、外键的关系"><a href="#主键、超键、候选键、外键的关系" class="headerlink" title="主键、超键、候选键、外键的关系"></a>主键、超键、候选键、外键的关系</h2><ol><li><p><strong>主键：</strong>数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。<strong>一个数据列只能有一个主键</strong>，且主键的取值不能缺失，即不能为空值（Null）。</p></li><li><p><strong>超键：</strong>在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。<strong>超键包含候选键和主键</strong>。<br>e.g.</p><table><thead><tr><th>姓名(假设姓名不重复)</th><th>学号</th><th>年龄</th></tr></thead><tbody><tr><td>aaa</td><td>1</td><td>20</td></tr><tr><td>bbb</td><td>2</td><td>30</td></tr><tr><td>ccc</td><td>3</td><td>23</td></tr></tbody></table><p>姓名唯一，是个超键<br>学号唯一，是个超键<br>（姓名，年龄）唯一 ，是个超键<br>（学号，年龄）唯一，是个超键<br>姓名唯一，且没有其他多余属性，是个候选键</p></li><li><p><strong>候选键：</strong>它是<strong>最小超键</strong>，即没有冗余元素的超键。</p></li><li><p><strong>外 键：</strong>在一个表中存在的<strong>另一个表的主键</strong>称此表的外键。</p></li></ol><h2 id="SQL-约束有哪几种？"><a href="#SQL-约束有哪几种？" class="headerlink" title="SQL 约束有哪几种？"></a>SQL 约束有哪几种？</h2><ol><li><strong>NOT NULL:</strong> 用于控制字段的内容一定不能为空（NULL）。</li><li><strong>UNIQUE:</strong> 控件字段内容不能重复，一个表允许有多个 Unique 约束。</li><li><strong>PRIMARY KEY:</strong> 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</li><li><strong>FOREIGN KEY:</strong> 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</li><li><strong>CHECK:</strong> 用于控制字段的值范围。</li></ol><h2 id="什么是存储过程？"><a href="#什么是存储过程？" class="headerlink" title="什么是存储过程？"></a>什么是存储过程？</h2><ul><li><strong>存储过程</strong>是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，存储在数据库中，经过第一次编译后再次调用不需要再次编译，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来调用存储过程。<strong>说白点</strong>，存储过程就是一段用于专门做一件事情的SQL语句。</li><li><strong>优点：</strong>存储过程是一个预编译的代码块，执行效率比较高 ，可以降低网络通信量，提高通信速率，可以一定程度上确保数据安全</li></ul><h2 id="MySQL-执行查询的过程"><a href="#MySQL-执行查询的过程" class="headerlink" title="MySQL 执行查询的过程"></a>MySQL 执行查询的过程</h2><ol><li>客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配。</li><li>查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）</li><li>语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。</li><li>优化。是否使用索引，生成执行计划。</li><li>交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。</li></ol><p><img src="https://static001.geekbang.org/infoq/41/4102b7d60fa20a0caabb127ecbb4d2f3.jpeg?x-oss-process=image/resize,p_80/auto-orient,1" alt="MySQL查询流程"></p><h2 id="MySQL-中的-varchar-和-char-有什么区别？"><a href="#MySQL-中的-varchar-和-char-有什么区别？" class="headerlink" title="MySQL 中的 varchar 和 char 有什么区别？"></a>MySQL 中的 varchar 和 char 有什么区别？</h2><p><code>char</code> 是一个定长字段，假如申请了<code>char(10)</code>的空间，那么无论实际存储多少内容，该字段都占用 10 个字符；而 <code>varchar</code> 是变长的，也就是说申请的只是最大长度，占用的空间为实际字符长度+1。</p><p>在检索效率上来讲，char &gt; varchar，因此在使用中，如果确定某个字段的值的长度，可以使用 <code>char</code>；否则应该尽量使用 <code>varchar</code>。例如存储用户 MD5 加密后的密码，则应该使用<code> char</code>。</p><h2 id="MySQL中-in-和-exists-区别"><a href="#MySQL中-in-和-exists-区别" class="headerlink" title="MySQL中 in 和 exists 区别*"></a>MySQL中 in 和 exists 区别*</h2><ul><li>MySQL中的<code>in</code>语句先执行子查询，子查询的返回结果去重之后，再执行主查询。<code>in</code>查询在内部表和外部表上都可以使用到索引。当<strong>子查询结果集</strong>较小，而外部表很大的时候；</li><li>MySQL中的<code>exists</code>语句是对外表作loop循环，每次loop循环在关联内表进行查询。<code>exists</code>查询仅在内部表上可以使用到索引当<strong>子查询结果集</strong>很大，而外部表较小的时候，适合用<code>exists</code>。</li><li><code>not in </code>和<code>not exists</code>：如果查询语句使用了<code>not in</code>，那么内外表都进行全表扫描，没有用到索引；而<code>not exists</code>的<strong>子查询</strong>依然能用到表上的索引。所以无论那个表大，用<code>not exists</code>都比<code>not in</code>要快。</li></ul><h2 id="drop、delete与truncate的区别"><a href="#drop、delete与truncate的区别" class="headerlink" title="drop、delete与truncate的区别"></a>drop、delete与truncate的区别</h2><p>三者都表示删除，区别如下</p><table><thead><tr><th align="center"></th><th align="center">Delete</th><th align="center">Truncate</th><th align="center">Drop</th></tr></thead><tbody><tr><td align="center">类型</td><td align="center">属于DML</td><td align="center">属于DDL</td><td align="center">属于DDL</td></tr><tr><td align="center">回滚</td><td align="center">可回滚</td><td align="center">不可回滚</td><td align="center">不可回滚</td></tr><tr><td align="center">删除内容</td><td align="center">表结构还在，删除表的部分或全部数据行</td><td align="center">表结构还在，删除表中的所有数据</td><td align="center">从数据库中删除整个表，连同数据、索引和权限</td></tr><tr><td align="center">删除速度</td><td align="center">删除速度慢，需要逐行删除</td><td align="center">删除速度快</td><td align="center">删除速度最快</td></tr></tbody></table><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a><strong>参考</strong></h2><p><a href="https://github.com/cosen1024/Java-Interview">https://github.com/cosen1024/Java-Interview</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
